## 26. Data Warehousing Overview: ETL and ELT

Data warehousing is when a large, centralised database contains information from many sources. This is often used for business analysts in large corporations or organisations. Generally, SQL or tools like Tableau will be used as a means of querying such databases.

It's not uncommon for entire departments to be dedicated to maintaining these data warehouses given how tricky data normalisation is (how does the data relate to each other? what views do people need?, etc.), how much work is needed for maintaining data feeds, the difficult that comes with scaling.

### 26.1. ETL: Extract, Transform, Load

ETL and ELT refer to how data gets into a data warehouse.

Traditionally the flow was Extra, Transform, Load:

1. Raw data is extracted

2. Data is transformed into the required schema

3. Data is loaded into the data warehouse

However, if we're dealing with "big data", this can become problematic.

### 26.2. ELT: Extract, Load, Transform

Traditionally a huge Oracle instance would be the only choice for large data warehousing. However, more technologies now exist, such as Hive that offers companies the ability to host massive databases on a Hadoop cluster, which for scalability essentially flips the process on its head:

1. Raw data is extracted

2. Data is loaded as is

3. Data is transformed in-place with the power of Hadoop

There's also the availability of large, distributed NoSQL data stores (queried with Spark, MapReduce, etc.).

### 26.3. Additional Information

Data warehousing is a discipline in itself and too large to cover in these notes. For further information, it's recommended to check out courses on "Big data", "Spark", "MapReduce", etc.
