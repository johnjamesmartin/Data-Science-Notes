## 31. Apache Spark

According to the official documentation, Spark is a "fast and general engine for large-scale data processing".

It is scalable like so:

![Scalable Spark](https://i.imgur.com/Y5aYEF5.gif 'Scalable Spark')

It can run up to 100x faster in memory or 10x fast on disk than other technologies like Hadoop MapReduce — its DAG engine (Direct Acyclic Graph) optimises workflows.

It's also very popular — used by Amazon, eBay (log analysis and aggregation), NASA JPL: Deep Space Network, Groupon, Trip Adviser, Yahoo, etc. For more, see: httpsL//cwiki.apache.org/confluence/display/SPARK/Powered+By+Spark. Plus, it's not that hard in that it gives us options to code in Python, Java, or Scala. Whichever the case, it's built around one main concept: the Resilient Distributed Dataset (RDD).

### 31.1. Apache Spark: Python vs. Scala

There are various advantages and disadvantages with the language we use to work with in Spark. Here are the main ones to keep in mind:

#### 31.1.1.Why use Python?

- No need to compile, manage dependencies, etc.

- Less coding overhead

- Familiar for most developers

#### 31.1.2. Why use Scala?

- More popular choice for Spark

- Spark is built on Scala, so coding is "native"

- New features and libraries tend to be Scala-first
