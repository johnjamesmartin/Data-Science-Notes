## 30. Data Cleaning and Normalisation

In data science, you spend most of your time cleaning and preparing your raw data, because skewed data ultimately leads to skewed decision making and in business this can cause a lot of damage! This cleaning and preparation stage includes checking for pollutants such as the following:

- Outliers

- Missing data

- Malicious data

- Erroneous data

- Irrelevant data

- Inconsistent data

- Formatting

## 30.1. Garbage In, Garbage Out (GIGO)

Always examine your data and always question your results â€” not just when they're results you don't like or don't expect.

## 30.1. Normalising Numerical Data

If your model is based on several numerical attributes, are they comparable? For example, ages might range from 0-100 and incomes from 0-billions. Some models may not perform well when different attributes are on very different scales and it can result in some attributes counting more than others as well as an increase in biases.

SciKit-Learn has a "whiten" option that normalises data for us. Use this!

## 30.2. Detecting Outliers

Sometimes it is appropriate to remove outliers from training data. But do this responsibly and understand why you're doing it. For example, in collaborative filtering, a single user who rates thousands of movies could have a big effect on everyone else's rating and that might not be desirable. But what if we're trying to calculate mean income? We would be wrong to exclude billionaires.

Standard deviation provides a principled way to classify outliers. We find data points more than some multiple of a standard deviation in our training data. As for what this multiple is? It comes down to common sense.
