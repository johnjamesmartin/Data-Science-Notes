## Glossary

Artificial intelligence (AI) - the simulation of human intelligence processes by machines — especially computer systems. These processes include learning, reasoning, and self-correction.

Bagging - stands for bootstrap aggregating and is an ensemble learning technique. Is used when our goal is to reduce variance of a decision tree (reducing overfitting and increasing accuracy) by taking a number of decision tree predictions and averaging them.

Bell curve - the most common type of distribution for a variable, AKA. normal distribution. It is called a "bell curve" because of the bell-shaped line this forms on a graph.

Big data - describes an extremely large data set (usually related to human behaviours and interactions) in which computational analyses can be applied to reveal patterns, trends, and associations.

Bin - see bucket.

Boosting- an ensemble learning technique to create a collection of predictors.

Bucket - an entity into which data is divided.

Categorical data - qualitative data with no inherent mathematical meaning, e.g. product category, addresses, etc.

Continuous data - numerical data with infinite numbers of values, e.g. times taken (1.003 hours, 0.9992 hours, etc.)

Coefficient - the multiplying number in algerbic expressions, e.g. 4 in 4x/10.

Data munging/wraggling - the process of transforming and mapping data from one "raw" data form into another format with the intent of making it more appropriate and valuable for a variety of downstream purposes such as analytics.

Data science - a multi-disciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data.

Deep learning -

Discrete data - interger based numerical data, e.g. number of purchases made by a customer.

Dynamic programming -

Exponential - an increase that becomes more and more rapid.

Feature - a machine learning term that describes an individual measurable property of characteristic of something be observed. In "computer vision" technology this might be an edge or an object.

Group/grouping - see bucket.

Kurtosis - how sharp the peak of a frequency-distribution curve is compared to normal distribution. Higher peaks have a higher kurtosis.

K-fold cross validation -

K-means clustering -

Linear regression - a form of regression analysis in which a straight line representing a set of observations is drawn on a graph and used to predict new values.

Log -

Machine learning - an application of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed.

Markov decision process -

Mean (mu) - also known as "the average". It is calculated by sum of values in data set divided by number of values in data set.

Median (u) - a number calculated by sorting values and taking the value at the midpoint. If there happens to be an even number of values, we calculate the median by taking an average of two midpoint values.

MLLib -

Mode - the most common value in a data set. It is therefore only relevant to discrete numerical data sets.

Neural network - a series of algorithms that calculate underlying relationships in a datasetthrough a process that mimics human brain processes. It adapts to changing inputs without needing to redesign output criteria.

Null hypothesis -

Ordinal data - a mix of numerical and categorical (categories given data), e.g. product rating on a 1-5 scale.

Overfitting - an analysis too exact to particular data set such that it fails to make reliable predictions

P value -

Q-learning - a specific implementation of reinforcement learning in which states and actions are quantified and assigned to variables. The Q variable increases with rewards and decreases for bad behaviour.

Random distribution -

Reinforcement learning - an area within machine learning in which a software agent is introduced to "explore" an environment and subsequently learn how to optimally achieve a given goal within it.

Skewness -

Spark -

Stacking - an ensemble learning technique that combines multiple classification or regression models. The base level models are trained based on a complete training set and the meta-model is trained on outputs of the base level model as features (see feature).

TF-IDF -

T-test -

Variance (s² or σ²) - how spread out a data set is. It is calculated by taking the average of square differences from the mean.

Vector -
