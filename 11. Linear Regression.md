## 11. Linear Regression

Linear regression (a form of regression analysis) is common in data science/data analysis. We use it when trying to fit some sort of function — a straight line in the case of _linear_ regression to a set of observations and using it to predict new values.

### 11.1. Notation

The fit is measured with r-squared (coefficient of determination). This is the fraction of the total variation in Y that's captured by the model and equation:

`1.0 - sum of squared errors/sum of squared variation from mean`

This is interpretated on a range of 0 to 1 with 0 as bad (no variance captured) and 1 is good (all variance captured). Usually, linear regression uses "least squares" (Aka. "OLS"). It minimizes the squared-error between each point and the line - Sometimes uses Gradient Descent when dealing with 3D data.

### 11.2. Computation

We can compute linear regression with "stats" from SciPy Python package. We use stats.linregress(sampleA, sampleB) and returns data on: `slope`, `intercept`, `r_value`, `p_value`, and `std_err`.

See `LinearRegression.ipynb` for more.
