## 17. K-Means Clustering

K-Means clustering is a technique in machine learning for splitting data into K groups closest to K centroids. It works through unsupervised learning — using only positions of each data point — and can uncover interesting groupings of people/things/behaviours. For example, where do millionaires live? What genres of music naturally fall out of data?

### 17.1. Computation

K-Means clustering is computed using a number of steps:

1. Randomly pick K centroids (K-means)

2. Assign each data point to the centroid it's closest to

3. Recompute the centroids based on the average position of each centroid's points

4. Iterate until points stop changing assignment to centroids

If you want to predict the cluster for new points, find the centroid they're closest to.

SciKit-Learn is a package that makes computing K-Means clustering easy.

### 17.2. Caveats

In choosing K, try increasing K values until you stop getting large reductions in squared error (distances from each point to their centroid). Also avoid "local minima", because a random choice of initial centroids can yield different results (run a few times just to make sure initial results aren't wacky).

K-Means does not attempt to assign any meaning to clusters, so it is up to us to identify and label these.
